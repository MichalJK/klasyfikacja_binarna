{"title":"Klasyfikacja binarna","markdown":{"yaml":{"title-block-banner":"#54698a","title-block-banner-color":"#dee1e3","title":"Klasyfikacja binarna ","subtitle":"Naive Bayes i KNN","author":"Michał Kołodziejczyk","date":"now","format":{"html":{"toc":true,"toc-location":"left","tbl-pos":"H","fig-pos":"H","tbl-cap-location":"margin","fig-cap-location":"margin","code-fold":true}},"editor":"visual","jupyter":"python3","css":"styles.css"},"headingText":"Baza \"mtcars\"","containsRefs":false,"markdown":"\n\nKlasyfikacja binarna polega na zakwalifikowaniu danych do jednej z dwu istniejących kategorii. Przyporządkowanie to następuje jako wynik działania algorytmu badającego strukturę bazy danych. W przypadku metody Naive Bayes algorytm oparty jest na twierdzeniu Bayesa o prawdopodobieństwie warunkowym. Algorytm KNN (K Neareast Neighbors) klasyfikuje nową daną na podstawie jej podobieństwa do danych zawartych w bazie. Podobieństwo to mierzy się za pomocą odległości od dwu zdefiniowanych kategorii.\n\nJako podstawę działania wybrano bazę 'mtcars'.\n\n\nBaza 'mtcars' jest bazą ze środowiska R. Zawiera dane charakteryzujące silniki wymienionych poniżej marek samochodów.\n\n```{python}\n#| label: tbl-1\n#| tbl-cap: \"Baza 'mtcars' \"\n#| message: false\n#| warning: false \n\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nimport itables\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split\nfrom itables import init_notebook_mode\nfrom itables import show  \n\ninit_notebook_mode(all_interactive=True)\n\n# Ładowanie bazy\n\nmtcars = sm.datasets.get_rdataset(\"mtcars\").data\nprint(\"\\n Baza 'mtcart', wymiary: \",mtcars.shape[0],\" x  \",mtcars.shape[1],\" \\n\")\n\nmtcars = mtcars.dropna() \n\nshow(mtcars, layout={\"topStart\": None, \"topEnd\": None},scrollY=\"300px\", scrollCollapse=True, paging=False)\n\n```\n\n| zmienna | opis |\n|----|----|\n| mpg | Miles/(US) gallon |\n| cyl | Number of cylinders |\n| disp | Displacement (cu.in.) |\n| hp | Gross horsepower |\n| drat | Rear axle ratio |\n| wt | Weight (lb/1000) |\n| qsec | 1/4 mile time |\n| vs | Engine: 0 = V-shaped (widlasty w układzie V), 1 = straight (rzędowy) |\n| am | Transmission (0 = automatic, 1 = manual) |\n| gear | Number of forward gears |\n| carb | Number of carburetors |\n\n: Baza 'mtcars' - opis zmiennych {#tbl-mtcars .striped .hover}\n\n# Cel obliczeń\n\n1.  Sprawdzić, jaki rodzaj silnika, czyli 'vs' = (V-sheped lub straight) jest lepszy, jeśli chodzi o zyżycie benzyny (daje wyższe 'mpg', czyli dłuższy przebieg na jednym galonie paliwa)?\n\n2.  Zastosowanie klasyfikatorów binarnych NB (prosty Bayes) i KNN (k najbliższych sąsiadów) tak, by na podstawie 'mpg' można było stwierdzić, jakiego rodzaju silnik dał konkretny przebieg.\n\nOznaczenie kategorii zmiennej 'vs': \"0\" - V- shaped - widlasty w układzie V; \"1\" - straigt - rzędowy.\n\nZmienne bazy 'mtcars' ograniczono do 'mpg' i 'vs'. Wynikowa baza nazywa się 'data'.\n\n## Baza ćwiczebna 'data'\n\n```{python}\n#| label: tbl-2\n#| tbl-cap: \"Baza ćwiczebna 'data' \"\n#| message: false\n#| warning: false\n\n# Wybór kolumn \ndata = mtcars[['mpg', 'vs']]\n\nshow(data, layout={\"topStart\": None, \"topEnd\": None},scrollY=\"300px\", scrollCollapse=True, paging=False)\n\n```\n\n80% rekordów bazy 'data' przeznaczono do nauki modelu, natomiast 20% zachowano w celu przetestowania i oszacowania jego jakości. Losowanie przeprowadzono bez powtórzeń.\n\n## Baza treningowa 'train'\n\n```{python}\n#| label: tbl-3\n#| tbl-cap: \"Baza treningowa \"\n#| message: false\n#| warning: false\n\nnp.random.seed(7)\n\n# Wybór indeksów bazy treningowej\nindex = np.random.choice(data.index, size=int(0.8 * len(data)), replace=False)\n\n\n# Dane treningowe 'train'\ntrain = data.loc[index]\n\n# Zamiana 'vs' na zmienną kategorialną\ntrain['vs'] = train['vs'].astype('category')\n\nshow(train, layout={\"topStart\": None, \"topEnd\": None},scrollY=\"300px\", scrollCollapse=True, paging=False)\n\n```\n\n## Baza testowa 'test'\n\n```{python}\n#| label: tbl-4\n#| tbl-cap: \"Baza testowa 'test' \"\n#| message: false\n#| warning: false\n\n# Dane testowe \ntest = data.drop(index)\n\nshow(test, layout={\"topStart\": None, \"topEnd\": None}, scrollY=\"200px\", scrollCollapse=True, paging=False)\n\n```\n\n```{python}\n#| label: Wykres\n#| echo: false\n#| message: false\n#| warning: false\n\n# Wykresy\n\ndef wykresy(train, test, dane, probs, pp, n):\n  \n    plt.scatter(train['mpg'], train['vs'], s=3, color='blue', label='Dane treningowe')\n    plt.scatter(test['mpg'], test['vs'], s=3, color='red', label='Dane testowe')\n    plt.scatter(dane['mpg'], probs[0:n,0], s = 30,  color='orange', label='Prawdopod., że vs = 0')\n    plt.scatter(dane['mpg'], probs[0:n,1], s = 30,  color='brown', label='Prawdopod., że vs = 1')\n    plt.scatter(dane['mpg'], pp, s = 100,  color='green', label='Wynik klasyfikacji', alpha = 0.3)\n    \n    plt.legend(loc='right')\n    plt.ylabel(\"p, vs\")\n    plt.show()  \n    \n    return\n  \n```\n\n```{python}\n#| label: Wykres_ani\n#| echo: false\n#| message: false\n#| warning: false\n\nimport matplotlib.animation as animation\nfrom matplotlib.animation import FuncAnimation\n\n# Wykresy z animacją\n\ndef wykresy_mpg_vs(train, test, dane, probs, pp, n, sss):\n\n    fig, ax = plt.subplots()\n    \n    # Animacja \n    frames = 7\n    \n    def update(frames):\n        ax.scatter(dane['mpg'], pp, s=100, color='green', label='Wynik klasyfikacji', alpha = 0.05)\n    \n    animation = FuncAnimation(fig, update,  frames=frames, interval=200)\n    \n    # Wykres\n    plt.scatter(train['mpg'], train['vs'], s=3, color='blue', label='Dane treningowe')\n    plt.scatter(test['mpg'], test['vs'], s=3, color='red', label='Dane testowe')\n    plt.scatter(dane['mpg'], probs[0:n,0], s = 30,  color='orange', label='Prawdopod., że vs = 0')\n    plt.scatter(dane['mpg'], probs[0:n,1], s = 30,  color='brown', label='Prawdopod., że vs = 1')\n    plt.scatter(dane['mpg'], pp, s = 100,  color='green', label='Wynik klasyfikacji', alpha = 0.2)\n    \n    plt.legend(loc='right')\n    plt.ylabel(\"p, vs\")\n    plt.xlabel(\"mpg\")\n    \n    # Zapis\n    animation.save(f\"{sss}{\".gif\"}\", writer=\"pillow\") \n    plt.savefig(f\"{sss}{\".png\"}\") \n    \n    plt.close()\n    \n    return\n\n```\n\n# NB - prosty klasyfikator Bayesa\n\nProsty (naiwny) klasyfikator Bayesa działa na zasadzie probabilitycznej, tzn. wyznacza prawdopodobieństwo warunkowe i na tej podstawie przeprowadza klasyfikację do jednej lub drugiej klasy.\n\n## Model klasyfikacji NB i jego trening\n\n```{python}\n#| label: model\n#| message: false\n#| warning: false\n\n# Model Naive Bayes\nnb = GaussianNB()\nnb.fit(train[['mpg']], train['vs'])\n\n```\n\n## Testowanie modelu\n\n### Wynik klasyfikacji\n\n```{python}\n#| label: tbl-5\n#| tbl-cap: 'Wyniki: p(\"0\") - prawdopodobieństwo vs = \"0\", p(\"1\") - prawdopodobieństwo vs = \"1\"'\n#| message: false\n#| warning: false\n\n# Predykcja na danych testowych\npredictions = nb.predict(test[['mpg']])\n\n# Prawdopodobieństwo warunkowe (a posteriori) \nprobs = nb.predict_proba(test[['mpg']])  \n\n# Generowanie df dla wyników testowania \nwynik = pd.DataFrame({'mpg': test['mpg'], 'test[vs]': test['vs'], 'predicted_class': predictions, 'p(\"0\")':np.round(probs[0:8,0],3), 'p(\"1\")':np.round(probs[0:8,1],3)})\n\nshow(wynik, layout={\"topStart\": None, \"topEnd\": None}, scrollY=\"400px\", scrollCollapse=True, paging=False)\n\n```\n\n### Tabela błędów\n\n```{python}\n#| label: tbl-7\n#| tbl-cap: \"Confusion matrix \"\n#| message: false\n#| warning: false\n\nfrom sklearn.metrics import (\n    accuracy_score,\n    cohen_kappa_score,\n    confusion_matrix,\n    ConfusionMatrixDisplay\n)\n\ncm = confusion_matrix(test[['vs']], wynik.predicted_class )\n\ncm = pd.DataFrame(cm)\ncm.rename(columns={0:'przewidywane: 0',1:'przewidywane: 1'}, inplace=True) \ncm.rename(index={0:'rzeczywiste: 0',1:'rzeczeczywiste: 1'}, inplace=True)\nshow(cm)\n\n# disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n#                                display_labels=model.classes_)\n# disp.plot() \n\n```\n\n### Dokładność i kappa\n\n```{python}\n\naccuracy = accuracy_score(test[['vs']], wynik.predicted_class)\nprint('accuracy = ', np.round(accuracy,3))\n\nkappa = cohen_kappa_score(test[['vs']], wynik.predicted_class)\nprint('kappa = ', np.round(kappa,3))\n\n```\n\n### Wykresy\n\nNa wykresie @fig-10 przedstawiono na tle danych treningowych i testowych wynik przewidywania (zielone kółko) oraz prawdopodobieństwa, służące jako podstawa klasyfikacji.\n\n```{python}\n#| echo: false\n#| eval: false\n#| label: fig-1\n#| fig-cap: \"Wykres zbiorczy testowania modelu NB (zielone kółko to wynik klasyfikacji)\"\n#| message: false\n#| warning: false\n\npp = predictions\nn = len(test)+1\n\nwykresy(train, test, test, probs, pp, n)\n\n```\n\n```         \n```\n\n```{python}\n#| message: false\n#| warning: false\n\npp = predictions\nn = len(test)+1\nppp = \"fig1\"\n\nwykresy_mpg_vs(train,test,test,probs,pp,n,ppp)\n\n```\n\n![Wykres zbiorczy testowania modelu NB (zielone migające kółka to wynik klasyfikacji NB)](fig1.gif){#fig-10}\n\n## Predykcja na nowych danych\n\n### Nowe dane\n\nWygenerowano nowe dane testowe zamieszczone w tab. @tbl-8 . Wykres zbiorczy klasyfikacji przedstawiono na rys. @fig-20 .\n\n```{python}\n#| label: tbl-8\n#| tbl-cap: \"Nowe dane\"\n#| message: false\n#| warning: false\n\n# Nowe dane\nnowe_dane = pd.DataFrame({'mpg': np.arange(10, 31, 5)})\nshow(np.transpose(nowe_dane))\n\n```\n\n### Klasyfikacja\n\n```{python}\n#| label: tbl-9\n#| tbl-cap: \"Wynik klasyfikacji dla nowych danych\"\n#| message: false\n#| warning: false\n\n# Predykcja\npredykcja = nb.predict(nowe_dane[['mpg']])\nprobs = nb.predict_proba(nowe_dane[['mpg']])  # posterior\n\n\n# Generowanie df dla nowych danych\nwynik = pd.DataFrame({'mpg': nowe_dane['mpg'], 'predicted_class': predykcja, 'p(\"0\")':np.round(probs[0:5,0],3), 'p(\"1\")':np.round(probs[0:5,1],3)})\n\nshow(wynik, layout={\"topStart\": None, \"topEnd\": None}, scrollY=\"400px\", scrollCollapse=True, paging=False)\n\n```\n\n### Wykresy\n\n```{python}\n#| echo: false\n#| eval: false\n#| label: fig-2\n#| fig-cap: \"Wykres zbiorczy dla nowych danych (zielone kółko to wynik klasyfikacji)\"\n#| message: false\n#| warning: false\n\npp_new = predykcja.astype(int)\nn = len(nowe_dane)\n\nwykresy(train, test, nowe_dane, probs, pp_new, n)\n\n```\n\n```{python}\n#| message: false\n#| warning: false\n\npp_new = predykcja.astype(int)\nn = len(nowe_dane)\n\nwykresy_mpg_vs(train,test,nowe_dane,probs,pp_new,n,\"fig2\")\n\n```\n\n![Wykres zbiorczy dla nowych danych (zielone migające kółka to wynik klasyfikacji NB)](fig2.gif){#fig-20}\n\n# KNN ( K Neareast Neighbor) - k najbliższych sąsiadów\n\nWykorzystano tę samą bazę danych @tbl-2 z takim samym podziałem na część treningową @tbl-3 i testową @tbl-4 .\n\n## Trening modelu klasyfikacji KNN\n\n```{python}\n#| message: false\n#| warning: false\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Trenowanie modelu\n\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(train[['mpg']], train['vs'])\n\n```\n\n## Predykcja na danych testowych\n\n### Wynik klasyfikacji\n\n```{python}\n#| label: tbl-10\n#| tbl-cap: \"Wynik klasyfikacji KNN danych testowych\"\n#| message: false\n#| warning: false\n\n# Predykcja\npredictions = knn.predict(test[['mpg']])\n\nprobs = knn.predict_proba(test[['mpg']])  \n\n# Generowanie wyników testowania jako df \nwynik = pd.DataFrame({'mpg': test['mpg'], 'test[vs]': test['vs'], 'predicted_class': predictions, 'p(\"0\")':np.round(probs[0:8,0],3), 'p(\"1\")':np.round(probs[0:8,1],3)})\n\nshow(wynik, layout={\"topStart\": None, \"topEnd\": None}, scrollY=\"400px\", scrollCollapse=True, paging=False)\n\n\n```\n\n### Tabela błędów\n\n```{python}\n#| label: tbl-11\n#| tbl-cap: \"Confusion matrix \"\n#| message: false\n#| warning: false\n\ncm = confusion_matrix(test['vs'], predictions)\n\ncm = pd.DataFrame(cm)\ncm.rename(columns={0:'przewidywane: 0',1:'przewidywane: 1'}, inplace=True) \ncm.rename(index={0:'rzeczywiste: 0',1:'rzecywiste: 1'}, inplace=True)\nshow(cm)\n\n\n```\n\n### Dokładność i kappa\n\n```{python}\n#| message: false\n#| warning: false\n\naccuracy = accuracy_score(test[['vs']], wynik.predicted_class)\nprint('accuracy = ', np.round(accuracy,3))\n\nkappa = cohen_kappa_score(test[['vs']], wynik.predicted_class)\nprint('kappa = ', np.round(kappa,3))\n\n```\n\n### Wykresy\n\n```{python}\n#| echo: false\n#| eval: false\n#| label: fig-3\n#| fig-cap: \"Wykres zbiorczy testowania modelu KNN (zielone kółko to wynik klasyfikacji)\"\n#| message: false\n#| warning: false\n\npp = predictions\nn = len(test)+1\n\nwykresy(train, test, test, probs, pp, n)\n\n```\n\n```{python}\n#| message: false\n#| warning: false\n\npp = predictions\nn = len(test)+1\n\nwykresy_mpg_vs(train,test,test,probs,pp,n,\"fig3\")\n\n```\n\n![Wykres zbiorczy testowania modelu KNN (zielone migające kółka to wynik klasyfikacji KNN)](fig3.gif){#fig-30}\n\n## Predykcja na nowych danych\n\n### Nowe dane\n\nWygenerowano nowe dane testowe zamieszczone w tab. @tbl-8 . Wykres zbiorczy klasyfikacji przedstawiono na rys. @fig-40 .\n\n### Klasyfikacja\n\n```{python}\n#| label: tbl-12\n#| tbl-cap: \"Wynik klasyfikacji KNN dla nowych danych \"\n#| message: false\n#| warning: false\n\n# Predykcja\npredykcja = knn.predict(nowe_dane[['mpg']])\nprobs = knn.predict_proba(nowe_dane[['mpg']])  # posterior\n\n\n# Generowanie df dla nowych danych\nwynik = pd.DataFrame({'mpg': nowe_dane['mpg'], 'predicted_class': predykcja, 'p(\"0\")':np.round(probs[0:5,0],3), 'p(\"1\")':np.round(probs[0:5,1],3)})\n\nshow(wynik, layout={\"topStart\": None, \"topEnd\": None}, scrollY=\"400px\", scrollCollapse=True, paging=False)\n\n```\n\n### Wykresy\n\n```{python}\n#| echo: false\n#| eval: false\n#| label: fig-4\n#| fig-cap: \"Wykres zbiorczy dla nowych danych (zielone kółko to wynik klasyfikacji KNN)\"\n#| message: false\n#| warning: false\n\npp_new = predykcja.astype(int)\nn = len(nowe_dane)\n\nwykresy(train, test, nowe_dane, probs, pp_new, n)\n\n```\n\n```{python}\n#| message: false\n#| warning: false\n\npp_new = predykcja.astype(int)\nn = len(nowe_dane)\n\nwykresy_mpg_vs(train,test,nowe_dane,probs,pp_new,n,\"fig4\")\n\n```\n\n![Wykres zbiorczy dla nowych danych (zielone migające kółka to wynik klasyfikacji KNN)](fig4.gif){#fig-40}\n\n# Podsumowanie\n\n1.  Wykresy @fig-10 - @fig-40 wskazują na to, że:\n\n-   w zakresie 'mpg' od 0 do ok. 17 'vs' = 0 (silnik w układzie V),\n-   w zakresie 'mpg' od ok 26 do 30 'vs' = 1 (silnik rzędowy).\n-   w zakresie pośrednim 'mpg' od ok 17 do 26 rośnie pradopodobieństwo, że 'vs' będzie równe 1; punkt odcięcia znajduje się mniej więcej w 'mpg' = 22.\n\n2.  Oba klasyfikatory spisały się podobnie na podstawie porównania dokładności. Metryka 'kappa' była nieco większa w przypadku KNN. Baza ćwiczeniowa była bardzo nieliczna i najprawdopodobniej z tego względu wyniki bardzo zależą od losowania bazy treningowej.\n","srcMarkdownNoYaml":"\n\nKlasyfikacja binarna polega na zakwalifikowaniu danych do jednej z dwu istniejących kategorii. Przyporządkowanie to następuje jako wynik działania algorytmu badającego strukturę bazy danych. W przypadku metody Naive Bayes algorytm oparty jest na twierdzeniu Bayesa o prawdopodobieństwie warunkowym. Algorytm KNN (K Neareast Neighbors) klasyfikuje nową daną na podstawie jej podobieństwa do danych zawartych w bazie. Podobieństwo to mierzy się za pomocą odległości od dwu zdefiniowanych kategorii.\n\nJako podstawę działania wybrano bazę 'mtcars'.\n\n# Baza \"mtcars\"\n\nBaza 'mtcars' jest bazą ze środowiska R. Zawiera dane charakteryzujące silniki wymienionych poniżej marek samochodów.\n\n```{python}\n#| label: tbl-1\n#| tbl-cap: \"Baza 'mtcars' \"\n#| message: false\n#| warning: false \n\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nimport itables\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split\nfrom itables import init_notebook_mode\nfrom itables import show  \n\ninit_notebook_mode(all_interactive=True)\n\n# Ładowanie bazy\n\nmtcars = sm.datasets.get_rdataset(\"mtcars\").data\nprint(\"\\n Baza 'mtcart', wymiary: \",mtcars.shape[0],\" x  \",mtcars.shape[1],\" \\n\")\n\nmtcars = mtcars.dropna() \n\nshow(mtcars, layout={\"topStart\": None, \"topEnd\": None},scrollY=\"300px\", scrollCollapse=True, paging=False)\n\n```\n\n| zmienna | opis |\n|----|----|\n| mpg | Miles/(US) gallon |\n| cyl | Number of cylinders |\n| disp | Displacement (cu.in.) |\n| hp | Gross horsepower |\n| drat | Rear axle ratio |\n| wt | Weight (lb/1000) |\n| qsec | 1/4 mile time |\n| vs | Engine: 0 = V-shaped (widlasty w układzie V), 1 = straight (rzędowy) |\n| am | Transmission (0 = automatic, 1 = manual) |\n| gear | Number of forward gears |\n| carb | Number of carburetors |\n\n: Baza 'mtcars' - opis zmiennych {#tbl-mtcars .striped .hover}\n\n# Cel obliczeń\n\n1.  Sprawdzić, jaki rodzaj silnika, czyli 'vs' = (V-sheped lub straight) jest lepszy, jeśli chodzi o zyżycie benzyny (daje wyższe 'mpg', czyli dłuższy przebieg na jednym galonie paliwa)?\n\n2.  Zastosowanie klasyfikatorów binarnych NB (prosty Bayes) i KNN (k najbliższych sąsiadów) tak, by na podstawie 'mpg' można było stwierdzić, jakiego rodzaju silnik dał konkretny przebieg.\n\nOznaczenie kategorii zmiennej 'vs': \"0\" - V- shaped - widlasty w układzie V; \"1\" - straigt - rzędowy.\n\nZmienne bazy 'mtcars' ograniczono do 'mpg' i 'vs'. Wynikowa baza nazywa się 'data'.\n\n## Baza ćwiczebna 'data'\n\n```{python}\n#| label: tbl-2\n#| tbl-cap: \"Baza ćwiczebna 'data' \"\n#| message: false\n#| warning: false\n\n# Wybór kolumn \ndata = mtcars[['mpg', 'vs']]\n\nshow(data, layout={\"topStart\": None, \"topEnd\": None},scrollY=\"300px\", scrollCollapse=True, paging=False)\n\n```\n\n80% rekordów bazy 'data' przeznaczono do nauki modelu, natomiast 20% zachowano w celu przetestowania i oszacowania jego jakości. Losowanie przeprowadzono bez powtórzeń.\n\n## Baza treningowa 'train'\n\n```{python}\n#| label: tbl-3\n#| tbl-cap: \"Baza treningowa \"\n#| message: false\n#| warning: false\n\nnp.random.seed(7)\n\n# Wybór indeksów bazy treningowej\nindex = np.random.choice(data.index, size=int(0.8 * len(data)), replace=False)\n\n\n# Dane treningowe 'train'\ntrain = data.loc[index]\n\n# Zamiana 'vs' na zmienną kategorialną\ntrain['vs'] = train['vs'].astype('category')\n\nshow(train, layout={\"topStart\": None, \"topEnd\": None},scrollY=\"300px\", scrollCollapse=True, paging=False)\n\n```\n\n## Baza testowa 'test'\n\n```{python}\n#| label: tbl-4\n#| tbl-cap: \"Baza testowa 'test' \"\n#| message: false\n#| warning: false\n\n# Dane testowe \ntest = data.drop(index)\n\nshow(test, layout={\"topStart\": None, \"topEnd\": None}, scrollY=\"200px\", scrollCollapse=True, paging=False)\n\n```\n\n```{python}\n#| label: Wykres\n#| echo: false\n#| message: false\n#| warning: false\n\n# Wykresy\n\ndef wykresy(train, test, dane, probs, pp, n):\n  \n    plt.scatter(train['mpg'], train['vs'], s=3, color='blue', label='Dane treningowe')\n    plt.scatter(test['mpg'], test['vs'], s=3, color='red', label='Dane testowe')\n    plt.scatter(dane['mpg'], probs[0:n,0], s = 30,  color='orange', label='Prawdopod., że vs = 0')\n    plt.scatter(dane['mpg'], probs[0:n,1], s = 30,  color='brown', label='Prawdopod., że vs = 1')\n    plt.scatter(dane['mpg'], pp, s = 100,  color='green', label='Wynik klasyfikacji', alpha = 0.3)\n    \n    plt.legend(loc='right')\n    plt.ylabel(\"p, vs\")\n    plt.show()  \n    \n    return\n  \n```\n\n```{python}\n#| label: Wykres_ani\n#| echo: false\n#| message: false\n#| warning: false\n\nimport matplotlib.animation as animation\nfrom matplotlib.animation import FuncAnimation\n\n# Wykresy z animacją\n\ndef wykresy_mpg_vs(train, test, dane, probs, pp, n, sss):\n\n    fig, ax = plt.subplots()\n    \n    # Animacja \n    frames = 7\n    \n    def update(frames):\n        ax.scatter(dane['mpg'], pp, s=100, color='green', label='Wynik klasyfikacji', alpha = 0.05)\n    \n    animation = FuncAnimation(fig, update,  frames=frames, interval=200)\n    \n    # Wykres\n    plt.scatter(train['mpg'], train['vs'], s=3, color='blue', label='Dane treningowe')\n    plt.scatter(test['mpg'], test['vs'], s=3, color='red', label='Dane testowe')\n    plt.scatter(dane['mpg'], probs[0:n,0], s = 30,  color='orange', label='Prawdopod., że vs = 0')\n    plt.scatter(dane['mpg'], probs[0:n,1], s = 30,  color='brown', label='Prawdopod., że vs = 1')\n    plt.scatter(dane['mpg'], pp, s = 100,  color='green', label='Wynik klasyfikacji', alpha = 0.2)\n    \n    plt.legend(loc='right')\n    plt.ylabel(\"p, vs\")\n    plt.xlabel(\"mpg\")\n    \n    # Zapis\n    animation.save(f\"{sss}{\".gif\"}\", writer=\"pillow\") \n    plt.savefig(f\"{sss}{\".png\"}\") \n    \n    plt.close()\n    \n    return\n\n```\n\n# NB - prosty klasyfikator Bayesa\n\nProsty (naiwny) klasyfikator Bayesa działa na zasadzie probabilitycznej, tzn. wyznacza prawdopodobieństwo warunkowe i na tej podstawie przeprowadza klasyfikację do jednej lub drugiej klasy.\n\n## Model klasyfikacji NB i jego trening\n\n```{python}\n#| label: model\n#| message: false\n#| warning: false\n\n# Model Naive Bayes\nnb = GaussianNB()\nnb.fit(train[['mpg']], train['vs'])\n\n```\n\n## Testowanie modelu\n\n### Wynik klasyfikacji\n\n```{python}\n#| label: tbl-5\n#| tbl-cap: 'Wyniki: p(\"0\") - prawdopodobieństwo vs = \"0\", p(\"1\") - prawdopodobieństwo vs = \"1\"'\n#| message: false\n#| warning: false\n\n# Predykcja na danych testowych\npredictions = nb.predict(test[['mpg']])\n\n# Prawdopodobieństwo warunkowe (a posteriori) \nprobs = nb.predict_proba(test[['mpg']])  \n\n# Generowanie df dla wyników testowania \nwynik = pd.DataFrame({'mpg': test['mpg'], 'test[vs]': test['vs'], 'predicted_class': predictions, 'p(\"0\")':np.round(probs[0:8,0],3), 'p(\"1\")':np.round(probs[0:8,1],3)})\n\nshow(wynik, layout={\"topStart\": None, \"topEnd\": None}, scrollY=\"400px\", scrollCollapse=True, paging=False)\n\n```\n\n### Tabela błędów\n\n```{python}\n#| label: tbl-7\n#| tbl-cap: \"Confusion matrix \"\n#| message: false\n#| warning: false\n\nfrom sklearn.metrics import (\n    accuracy_score,\n    cohen_kappa_score,\n    confusion_matrix,\n    ConfusionMatrixDisplay\n)\n\ncm = confusion_matrix(test[['vs']], wynik.predicted_class )\n\ncm = pd.DataFrame(cm)\ncm.rename(columns={0:'przewidywane: 0',1:'przewidywane: 1'}, inplace=True) \ncm.rename(index={0:'rzeczywiste: 0',1:'rzeczeczywiste: 1'}, inplace=True)\nshow(cm)\n\n# disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n#                                display_labels=model.classes_)\n# disp.plot() \n\n```\n\n### Dokładność i kappa\n\n```{python}\n\naccuracy = accuracy_score(test[['vs']], wynik.predicted_class)\nprint('accuracy = ', np.round(accuracy,3))\n\nkappa = cohen_kappa_score(test[['vs']], wynik.predicted_class)\nprint('kappa = ', np.round(kappa,3))\n\n```\n\n### Wykresy\n\nNa wykresie @fig-10 przedstawiono na tle danych treningowych i testowych wynik przewidywania (zielone kółko) oraz prawdopodobieństwa, służące jako podstawa klasyfikacji.\n\n```{python}\n#| echo: false\n#| eval: false\n#| label: fig-1\n#| fig-cap: \"Wykres zbiorczy testowania modelu NB (zielone kółko to wynik klasyfikacji)\"\n#| message: false\n#| warning: false\n\npp = predictions\nn = len(test)+1\n\nwykresy(train, test, test, probs, pp, n)\n\n```\n\n```         \n```\n\n```{python}\n#| message: false\n#| warning: false\n\npp = predictions\nn = len(test)+1\nppp = \"fig1\"\n\nwykresy_mpg_vs(train,test,test,probs,pp,n,ppp)\n\n```\n\n![Wykres zbiorczy testowania modelu NB (zielone migające kółka to wynik klasyfikacji NB)](fig1.gif){#fig-10}\n\n## Predykcja na nowych danych\n\n### Nowe dane\n\nWygenerowano nowe dane testowe zamieszczone w tab. @tbl-8 . Wykres zbiorczy klasyfikacji przedstawiono na rys. @fig-20 .\n\n```{python}\n#| label: tbl-8\n#| tbl-cap: \"Nowe dane\"\n#| message: false\n#| warning: false\n\n# Nowe dane\nnowe_dane = pd.DataFrame({'mpg': np.arange(10, 31, 5)})\nshow(np.transpose(nowe_dane))\n\n```\n\n### Klasyfikacja\n\n```{python}\n#| label: tbl-9\n#| tbl-cap: \"Wynik klasyfikacji dla nowych danych\"\n#| message: false\n#| warning: false\n\n# Predykcja\npredykcja = nb.predict(nowe_dane[['mpg']])\nprobs = nb.predict_proba(nowe_dane[['mpg']])  # posterior\n\n\n# Generowanie df dla nowych danych\nwynik = pd.DataFrame({'mpg': nowe_dane['mpg'], 'predicted_class': predykcja, 'p(\"0\")':np.round(probs[0:5,0],3), 'p(\"1\")':np.round(probs[0:5,1],3)})\n\nshow(wynik, layout={\"topStart\": None, \"topEnd\": None}, scrollY=\"400px\", scrollCollapse=True, paging=False)\n\n```\n\n### Wykresy\n\n```{python}\n#| echo: false\n#| eval: false\n#| label: fig-2\n#| fig-cap: \"Wykres zbiorczy dla nowych danych (zielone kółko to wynik klasyfikacji)\"\n#| message: false\n#| warning: false\n\npp_new = predykcja.astype(int)\nn = len(nowe_dane)\n\nwykresy(train, test, nowe_dane, probs, pp_new, n)\n\n```\n\n```{python}\n#| message: false\n#| warning: false\n\npp_new = predykcja.astype(int)\nn = len(nowe_dane)\n\nwykresy_mpg_vs(train,test,nowe_dane,probs,pp_new,n,\"fig2\")\n\n```\n\n![Wykres zbiorczy dla nowych danych (zielone migające kółka to wynik klasyfikacji NB)](fig2.gif){#fig-20}\n\n# KNN ( K Neareast Neighbor) - k najbliższych sąsiadów\n\nWykorzystano tę samą bazę danych @tbl-2 z takim samym podziałem na część treningową @tbl-3 i testową @tbl-4 .\n\n## Trening modelu klasyfikacji KNN\n\n```{python}\n#| message: false\n#| warning: false\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Trenowanie modelu\n\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(train[['mpg']], train['vs'])\n\n```\n\n## Predykcja na danych testowych\n\n### Wynik klasyfikacji\n\n```{python}\n#| label: tbl-10\n#| tbl-cap: \"Wynik klasyfikacji KNN danych testowych\"\n#| message: false\n#| warning: false\n\n# Predykcja\npredictions = knn.predict(test[['mpg']])\n\nprobs = knn.predict_proba(test[['mpg']])  \n\n# Generowanie wyników testowania jako df \nwynik = pd.DataFrame({'mpg': test['mpg'], 'test[vs]': test['vs'], 'predicted_class': predictions, 'p(\"0\")':np.round(probs[0:8,0],3), 'p(\"1\")':np.round(probs[0:8,1],3)})\n\nshow(wynik, layout={\"topStart\": None, \"topEnd\": None}, scrollY=\"400px\", scrollCollapse=True, paging=False)\n\n\n```\n\n### Tabela błędów\n\n```{python}\n#| label: tbl-11\n#| tbl-cap: \"Confusion matrix \"\n#| message: false\n#| warning: false\n\ncm = confusion_matrix(test['vs'], predictions)\n\ncm = pd.DataFrame(cm)\ncm.rename(columns={0:'przewidywane: 0',1:'przewidywane: 1'}, inplace=True) \ncm.rename(index={0:'rzeczywiste: 0',1:'rzecywiste: 1'}, inplace=True)\nshow(cm)\n\n\n```\n\n### Dokładność i kappa\n\n```{python}\n#| message: false\n#| warning: false\n\naccuracy = accuracy_score(test[['vs']], wynik.predicted_class)\nprint('accuracy = ', np.round(accuracy,3))\n\nkappa = cohen_kappa_score(test[['vs']], wynik.predicted_class)\nprint('kappa = ', np.round(kappa,3))\n\n```\n\n### Wykresy\n\n```{python}\n#| echo: false\n#| eval: false\n#| label: fig-3\n#| fig-cap: \"Wykres zbiorczy testowania modelu KNN (zielone kółko to wynik klasyfikacji)\"\n#| message: false\n#| warning: false\n\npp = predictions\nn = len(test)+1\n\nwykresy(train, test, test, probs, pp, n)\n\n```\n\n```{python}\n#| message: false\n#| warning: false\n\npp = predictions\nn = len(test)+1\n\nwykresy_mpg_vs(train,test,test,probs,pp,n,\"fig3\")\n\n```\n\n![Wykres zbiorczy testowania modelu KNN (zielone migające kółka to wynik klasyfikacji KNN)](fig3.gif){#fig-30}\n\n## Predykcja na nowych danych\n\n### Nowe dane\n\nWygenerowano nowe dane testowe zamieszczone w tab. @tbl-8 . Wykres zbiorczy klasyfikacji przedstawiono na rys. @fig-40 .\n\n### Klasyfikacja\n\n```{python}\n#| label: tbl-12\n#| tbl-cap: \"Wynik klasyfikacji KNN dla nowych danych \"\n#| message: false\n#| warning: false\n\n# Predykcja\npredykcja = knn.predict(nowe_dane[['mpg']])\nprobs = knn.predict_proba(nowe_dane[['mpg']])  # posterior\n\n\n# Generowanie df dla nowych danych\nwynik = pd.DataFrame({'mpg': nowe_dane['mpg'], 'predicted_class': predykcja, 'p(\"0\")':np.round(probs[0:5,0],3), 'p(\"1\")':np.round(probs[0:5,1],3)})\n\nshow(wynik, layout={\"topStart\": None, \"topEnd\": None}, scrollY=\"400px\", scrollCollapse=True, paging=False)\n\n```\n\n### Wykresy\n\n```{python}\n#| echo: false\n#| eval: false\n#| label: fig-4\n#| fig-cap: \"Wykres zbiorczy dla nowych danych (zielone kółko to wynik klasyfikacji KNN)\"\n#| message: false\n#| warning: false\n\npp_new = predykcja.astype(int)\nn = len(nowe_dane)\n\nwykresy(train, test, nowe_dane, probs, pp_new, n)\n\n```\n\n```{python}\n#| message: false\n#| warning: false\n\npp_new = predykcja.astype(int)\nn = len(nowe_dane)\n\nwykresy_mpg_vs(train,test,nowe_dane,probs,pp_new,n,\"fig4\")\n\n```\n\n![Wykres zbiorczy dla nowych danych (zielone migające kółka to wynik klasyfikacji KNN)](fig4.gif){#fig-40}\n\n# Podsumowanie\n\n1.  Wykresy @fig-10 - @fig-40 wskazują na to, że:\n\n-   w zakresie 'mpg' od 0 do ok. 17 'vs' = 0 (silnik w układzie V),\n-   w zakresie 'mpg' od ok 26 do 30 'vs' = 1 (silnik rzędowy).\n-   w zakresie pośrednim 'mpg' od ok 17 do 26 rośnie pradopodobieństwo, że 'vs' będzie równe 1; punkt odcięcia znajduje się mniej więcej w 'mpg' = 22.\n\n2.  Oba klasyfikatory spisały się podobnie na podstawie porównania dokładności. Metryka 'kappa' była nieco większa w przypadku KNN. Baza ćwiczeniowa była bardzo nieliczna i najprawdopodobniej z tego względu wyniki bardzo zależą od losowania bazy treningowej.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":"H","fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"index.html"},"language":{"toc-title-document":"Spis treści","toc-title-website":"Na tej stronie","related-formats-title":"Inne formaty","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Źródło","other-links-title":"Inne odnośniki","code-links-title":"Linki do kodu","launch-dev-container-title":"Uruchom Dev Container","launch-binder-title":"Uruchom Binder","article-notebook-label":"Notatnik artykułu","notebook-preview-download":"Pobierz notatnik","notebook-preview-download-src":"Pobierz kod źródłowy","notebook-preview-back":"Powrót do artykułu","manuscript-meca-bundle":"Archiwum MECA","section-title-abstract":"Abstrakt","section-title-appendices":"Załączniki","section-title-footnotes":"Przypisy","section-title-references":"Bibliografia","section-title-reuse":"Licencja","section-title-copyright":"Prawa autorskie","section-title-citation":"Cytowanie","appendix-attribution-cite-as":"W celu atrybucji, proszę cytować tę pracę jako:","appendix-attribution-bibtex":"cytowanie BibTeX:","appendix-view-license":"Pokaż Licencję","title-block-author-single":"Autor","title-block-author-plural":"Autorzy","title-block-affiliation-single":"Afiliacja","title-block-affiliation-plural":"Afiliacje","title-block-published":"Opublikowano","title-block-modified":"Zmodyfikowano","title-block-keywords":"Słowa kluczowe","callout-tip-title":"Wskazówka","callout-note-title":"Adnotacja","callout-warning-title":"Ostrzeżenie","callout-important-title":"Ważne","callout-caution-title":"Zagrożenie","code-summary":"Kod","code-tools-menu-caption":"Kod","code-tools-show-all-code":"Pokaż cały kod","code-tools-hide-all-code":"Ukryj cały kod","code-tools-view-source":"Pokaż źródło","code-tools-source-code":"Kod źródłowy","tools-share":"Share","tools-download":"Download","code-line":"Linia","code-lines":"Linie","copy-button-tooltip":"Kopiuj do schowka","copy-button-tooltip-success":"Skopiowano!","repo-action-links-edit":"Edytuj tę stronę","repo-action-links-source":"Pokaż źródło","repo-action-links-issue":"Zgłoś problem","back-to-top":"Powrót do góry","search-no-results-text":"Brak wyników","search-matching-documents-text":"dopasowane dokumenty","search-copy-link-title":"Kopiuj link do wyszukiwania","search-hide-matches-text":"Ukryj dodatkowe dopasowania","search-more-match-text":"więcej dopasowań w tym dokumencie","search-more-matches-text":"więcej dopasowań w tym dokumencie","search-clear-button-title":"Wyczyść","search-text-placeholder":"","search-detached-cancel-button-title":"Anuluj","search-submit-button-title":"Zatwierdź","search-label":"Szukaj","toggle-section":"Przełącz sekcję","toggle-sidebar":"Przełącz pasek boczny","toggle-dark-mode":"Przełącz tryb ciemny","toggle-reader-mode":"Przełącz tryb czytnika","toggle-navigation":"Przełącz nawigację","crossref-fig-title":"Rysunek","crossref-tbl-title":"Tabela","crossref-lst-title":"Wykaz","crossref-thm-title":"Twierdzenie","crossref-lem-title":"Lemat","crossref-cor-title":"Wniosek","crossref-prp-title":"Proposition","crossref-cnj-title":"Przypuszczenie","crossref-def-title":"Definicja","crossref-exm-title":"Przykład","crossref-exr-title":"Ćwiczenie","crossref-ch-prefix":"Rozdział","crossref-apx-prefix":"Załącznik","crossref-sec-prefix":"Sekcja","crossref-eq-prefix":"Równanie","crossref-lof-title":"Spis rycin","crossref-lot-title":"Spis tabel","crossref-lol-title":"Spis wykazów","environment-proof-title":"Dowód","environment-remark-title":"Komentarz","environment-solution-title":"Rozwiązanie","listing-page-order-by":"Sortuj według","listing-page-order-by-default":"Domyślnie","listing-page-order-by-date-asc":"Od najstarszych","listing-page-order-by-date-desc":"Od najnowszych","listing-page-order-by-number-desc":"Od największych","listing-page-order-by-number-asc":"Od najmniejszych","listing-page-field-date":"Data","listing-page-field-title":"Tytuł","listing-page-field-description":"Opis","listing-page-field-author":"Autor","listing-page-field-filename":"Nazwa pliku","listing-page-field-filemodified":"Zmodyfikowano","listing-page-field-subtitle":"Podtytuł","listing-page-field-readingtime":"Czas czytania","listing-page-field-wordcount":"Licznik Słów","listing-page-field-categories":"Kategorie","listing-page-minutes-compact":"{0} min","listing-page-category-all":"Wszystkie","listing-page-no-matches":"Brak pasujących","listing-page-words":"{0} słów","listing-page-filter":"Filtr","draft":"Projekt"},"metadata":{"lang":"pl","fig-responsive":true,"quarto-version":"1.5.57","theme":"cosmo","title-block-banner":"#54698a","title-block-banner-color":"#dee1e3","title":"Klasyfikacja binarna ","subtitle":"Naive Bayes i KNN","author":"Michał Kołodziejczyk","date":"now","editor":"visual","jupyter":"python3","toc-location":"left","tbl-pos":"H","tbl-cap-location":"margin","fig-cap-location":"margin"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}